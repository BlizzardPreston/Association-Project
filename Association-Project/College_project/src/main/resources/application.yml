server:
  port: 8888
spring:
  thymeleaf:
    cache: false
    prefix: classpath:/templates/
    suffix: .html
    encoding: UTF-8
    servlet:
      content-type: text/html
    mode: HTML5

    #redis:
    #  primary:
    #    host: 172.168.1.196
    #    port: 6379
    #    database: 0
    #    ##password: Eg2Ehx7WMkQQ8ePn3@s4McS!zGs$m1K@
    #    init-redisson: true
    #    timeout: 5S
    # redis

  redis:
    # Redis数据库索引(默认0)
    database: 0

    #    1核1g阿里云
#    host: 47.96.106.141
#    port: 6379
    #      2核8g阿里云
    host: 8.135.112.184
    #    8.135.。。是6380端口
    port: 6380
    #    ms
    timeout: 5000
    # Redis服务器连接密码（默认为空）
    #    password: 123456
    #    jedis:
    #      pool:
    # # 连接池最大连接数（使用负值表示没有限制）
    #max-active: 20
    ## 连接池中的最大空闲连接
    #max-idle: 10
    ## 连接池中的最小空闲连接
    #min-idle: 0
    ## 连接池最大阻塞等待时间（使用负值表示没有限制）
    #max-wait: -1

    #Lettuce 是一个可伸缩线程安全的 Redis 客户端，多个线程可以共享同一个 RedisConnection，它利用优秀 netty NIO 框架来高效地管理多个连接
    lettuce:
      # 关闭超时时间
      shutdown-timeout: 100
      pool:
        # 连接池最大连接数（使用负值表示没有限制）
        max-active: 20
        # 连接池中的最大空闲连接
        max-idle: 10
        # 连接池中的最小空闲连接
        min-idle: 0
        # 连接池最大阻塞等待时间（使用负值表示没有限制）
        max-wait: -1
  #    connect-timeout: 50000





  datasource:
    username: root
    password: jianzi456123
    #?serverTimezone=UTC解决时区的报错
    url: jdbc:mysql://8.135.112.184:3306/College?serverTimezone=UTC&useUnicode=true&characterEncoding=utf-8
    driver-class-name: com.mysql.cj.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource

    #Spring Boot 默认是不注入这些属性值的，需要自己绑定
    #druid 数据源专有配置
    druid:
      # 初始连接数
      initial-size: 5
      # 最小连接数
      min-idle: 10
      # 最大连接数
      max-active: 20
      # 获取连接超时时间
      max-wait: 5000
      # 连接有效性检测时间
      time-between-eviction-runs-millis: 6000
      # 连接在池中最小生存的时间
      min-evictable-idle-time-millis: 300000
      # 连接在池中最大生存的时间
      max-evictable-idle-time-millis: 900000
      test-while-idle: true
      test-on-borrow: false
      test-on-return: false
      # 检测连接是否有效
      validation-query: select 1

#      #数据库密码加密
#      filter:
#        config:
#          enabled: true
#      connect-properties: { config.decrypt: true,config.decrypt.key: MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBAM87dCJJFb9nN5SfyG1obzaD5iAtAOYiGpBAA0afgmnPg0KHIEPAhLIkyY7BCeXfGrdkYwycF8yM8RikK8ijrfUCAwEAAQ== }


#  kafka配置
  kafka:
    bootstrap-servers: 8.135.112.184:9092 # kafka集群信息，多个用逗号间隔
    # 生产者
    producer:
      # 重试次数，设置大于0的值，则客户端会将发送失败的记录重新发送
      retries: 3
      batch-size: 16384 #批量处理大小，16K
      buffer-memory: 33554432 #缓冲存储大，32M
      acks: 1
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    # 消费者
    consumer:
      # 消费者组
      group-id: CollegeGroup
      # 是否自动提交
      enable-auto-commit: false
      # 消费偏移配置
      # none：如果没有为消费者找到先前的offset的值,即没有自动维护偏移量,也没有手动维护偏移量,则抛出异常
      # earliest：在各分区下有提交的offset时：从offset处开始消费；在各分区下无提交的offset时：从头开始消费
      # latest：在各分区下有提交的offset时：从offset处开始消费；在各分区下无提交的offset时：从最新的数据开始消费
      auto-offset-reset: latest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    # 监听
    listener:
      # record：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # batch：当每一批poll()的数据被ListenerConsumer处理之后提交
      # time：当每一批poll()的数据被ListenerConsumer处理之后，距离上次提交时间大于TIME时提交
      # count：当每一批poll()的数据被ListenerConsumer处理之后，被处理record数量大于等于COUNT时提交
      # count_time：TIME或COUNT中有一个条件满足时提交
      # manual：当每一批poll()的数据被ListenerConsumer处理之后, 手动调用Acknowledgment.acknowledge()后提交
      # manual_immediate：手动调用Acknowledgment.acknowledge()后立即提交，一般推荐使用这种
      ack-mode: manual_immediate
      concurrency: 10 #并发数
      #开启批量处理
      type: batch



#xxl-job
# 执行器"AppName"和地址信息配置：AppName执行器心跳注册分组依据；地址信息用于"调度中心请求并触发任务"和"执行器注册"。
# 执行器默认端口为9999，执行器IP默认为空表示自动获取IP，多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用。
#单机部署多个执行器时，注意要配置不同执行器端口
xxl:
  job:
    admin:
      addresses: http://8.135.112.184:8100/xxl-job-admin
    accessToken:
    executor:
#      appname: xxl-job-executor-sample
      appname: xxl-job-executor-sample
      ip:
      port: 9999
      # 执行器运行日志文件存储的磁盘位置，需要对该路径拥有读写权限
      logpath:
      # xxl-job log retention days：执行器Log文件定期清理功能，指定日志保存天数，日志文件过期自动删除。
      #限制至少保持3天，否则功能不生效；
      logretentiondays: 3



#自己配置的属性，部署后直接取到使用，统一管理
xinjianchen:
  shiro:
    redis:
      expire: 3600000




mybatis:
  mapper-locations: classpath*:mapper/*.xml  #配置映射文件
  type-aliases-package: com.association.entity #配置实体类

